{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Few-shot 프롬프팅\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경 설정 및 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API KEY: 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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"API KEY: {api_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그... API 키를 바꿨다면 이걸 해줘야함!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 현재 API 키: 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\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wd/9ss9knvd6h1fw04p5pnqjm8w0000gn/T/ipykernel_30407/1682128924.py:11: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 어떻게 도와드릴 수 있을까요?\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# ⛳ 덮어쓰기 허용!\n",
    "load_dotenv(override=True)\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(f\"✅ 현재 API 키: {api_key}\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    openai_api_key=api_key\n",
    ")\n",
    "\n",
    "result = llm.invoke(\"테스트 메시지입니다.\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) 기본 라이브러리`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) LLM 설정`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-4.1-mini',\n",
    "    temperature=0.3,\n",
    "    top_p=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Zero-shot** 프롬프팅\n",
    "\n",
    "- **Zero-shot 프롬프팅**은 예시 없이 AI가 즉시 작업을 수행하는 기법입니다\n",
    "\n",
    "- 명확한 **지시사항**만으로 원하는 결과를 얻을 수 있어 **사용이 간단**합니다\n",
    "\n",
    "- 단순하고 직관적인 작업에 적합한 프롬프팅 방식이지만, 작업의 **복잡도에 따라 선택적 사용**이 필요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 반도체 시장에서 삼성전자의 주요 경쟁업체는 다음과 같습니다:\n",
      "\n",
      "1. **엔비디아 (NVIDIA)**  \n",
      "   - GPU(그래픽 처리 장치) 기반 인공지능 연산 분야에서 세계적인 선두주자입니다. 딥러닝, 머신러닝, 자율주행, 데이터센터 AI 가속기 등 다양한 AI 응용에 최적화된 반도체를 제공합니다.\n",
      "\n",
      "2. **인텔 (Intel)**  \n",
      "   - CPU뿐만 아니라 AI 가속기, FPGA, 신경망 처리 장치(NPU) 등 다양한 AI 반도체 솔루션을 개발하고 있습니다. 최근에는 AI 전용 칩과 데이터센터용 AI 하드웨어에 집중하고 있습니다.\n",
      "\n",
      "3. **구글 (Google)**  \n",
      "   - 자체 개발한 TPU(Tensor Processing Unit)를 통해 클라우드 기반 AI 연산에 특화된 반도체를 제공합니다. AI 모델 학습과 추론에 최적화된 칩을 설계합니다.\n",
      "\n",
      "4. **AMD (Advanced Micro Devices)**  \n",
      "   - GPU 및 CPU 분야에서 경쟁하며, AI 및 머신러닝 워크로드에 적합한 고성능 반도체를 개발합니다.\n",
      "\n",
      "5. **화웨이 (Huawei)**  \n",
      "   - 자체 AI 칩셋인 Ascend 시리즈를 통해 AI 컴퓨팅 시장에 진출했으며, 특히 중국 내에서 강력한 경쟁력을 보유하고 있습니다.\n",
      "\n",
      "6. **미디어텍 (MediaTek)**  \n",
      "   - 모바일 및 엣지 AI 칩셋 분야에서 경쟁하며, AI 기능이 내장된 SoC(System on Chip)를 제공합니다.\n",
      "\n",
      "이 외에도 AI 반도체 스타트업과 다양한 반도체 기업들이 시장에 진입하며 경쟁이 심화되고 있습니다. 삼성전자는 메모리 반도체뿐 아니라 AI 연산에 특화된 프로세서 개발에도 적극 투자하고 있어, 위 기업들과 기술 및 시장 점유율 경쟁을 벌이고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Zero-shot 프롬프트 템플릿 생성\n",
    "zero_shot_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"다음 시장에서 삼성전자의 경쟁업체를 설명해주세요: {topic}\"\n",
    ")\n",
    "\n",
    "# 체인 생성\n",
    "chain = zero_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Zero-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "zero_shot_result = chain.invoke(input={\"topic\": topic}) \n",
    "\n",
    "print(zero_shot_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot 프롬프팅 - 컨텍스트(Context) 제공 \n",
    "zero_shot_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"topic\"],\n",
    "    template=\"\"\"{topic} 시장에서 삼성전자의 경쟁업체를 설명해주세요. \n",
    "    반드시 다음 제시된 뉴스에 근거해서 답변하세요:\n",
    "\n",
    "    [뉴스]\n",
    "    {context}\n",
    "    \n",
    "    [답변]\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# 체인 생성\n",
    "chain = zero_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Zero-shot 실행\n",
    "context = \"\"\"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. \n",
    "이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, \n",
    "세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\n",
    "\"\"\"\n",
    "\n",
    "topic = \"인공지능 반도체\"\n",
    "zero_shot_result = chain.invoke(input={\"context\": context, \"topic\": topic})\n",
    "\n",
    "print(zero_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **One-shot** 프롬프팅\n",
    "\n",
    "- **One-shot 프롬프팅**은 하나의 예시를 통해 AI가 작업 패턴을 학습하는 기법입니다\n",
    "\n",
    "- **Zero-shot** 방식보다 더 나은 성능을 제공하며, **형식화된 작업**에 특히 효과적입니다\n",
    "\n",
    "- 단일 예시로 **품질 향상**이 가능하나, 해당 예시에 **과의존**할 수 있는 한계가 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### One-shot 프롬프트 템플릿 생성\n",
    "# 1. Zero-shot 프롬프트 템플릿에 예시(example)를 포함하도록 수정\n",
    "# 2. input_variables에 example_topic과 example_response 추가\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "one_shot_prompt = PromptTemplate(\n",
    "    input_variables=[\"example_topic\", \"example_response\", \"topic\"],\n",
    "    template=\"\"\"다음은 특정 시장에서 삼성전자의 경쟁업체를 설명하는 예시이다:\n",
    "\n",
    "시장: {example_topic}\n",
    "경쟁업체: {example_response}\n",
    "\n",
    "이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\n",
    "시장: {topic}\"\"\"\n",
    ")\n",
    "\n",
    "# Example 데이터 설정\n",
    "example_topic = \"스마트폰\"\n",
    "example_response = \"\"\"애플: 프리미엄 시장에서 주요 경쟁사로, iPhone 시리즈로 경쟁\n",
    "샤오미: 중저가 시장에서 강세를 보이며 글로벌 시장 점유율 확대\n",
    "구글: Pixel 시리즈로 프리미엄 시장 진출, AI 기능 강조\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) PromptTemplate 그대로 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_shot_result:\n",
      "시장: 인공지능 반도체  \n",
      "경쟁업체:  \n",
      "- 엔비디아(NVIDIA): AI 반도체 시장의 선두주자로, GPU 기반의 고성능 AI 연산 칩을 제공하며 데이터센터 및 자율주행, 로보틱스 등 다양한 분야에서 강력한 입지를 보유  \n",
      "- AMD: 고성능 GPU와 CPU를 결합한 솔루션으로 AI 및 머신러닝 워크로드에 대응하며, 엔비디아와 경쟁하는 주요 업체  \n",
      "- 구글(Google): 자체 개발한 TPU(Tensor Processing Unit)를 통해 클라우드 AI 연산에 최적화된 반도체를 제공하며, AI 서비스와의 시너지를 극대화  \n",
      "- 인텔(Intel): AI 가속기 및 FPGA 기반 솔루션을 포함한 다양한 AI 반도체 제품을 개발하며, 데이터센터 및 엣지 컴퓨팅 시장에서 경쟁  \n",
      "- 화웨이(Huawei): AI 칩셋인 Ascend 시리즈를 통해 중국 내수 및 글로벌 시장에서 AI 반도체 경쟁력을 강화 중  \n",
      "\n",
      "이들 기업은 삼성전자와 함께 AI 반도체 기술 발전과 시장 확대를 주도하고 있다.\n"
     ]
    }
   ],
   "source": [
    "# one_shot_prompt 적용한 체인 생성\n",
    "chain = one_shot_prompt | llm | StrOutputParser()\n",
    "\n",
    "# One-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "one_shot_result = chain.invoke(\n",
    "    input={\n",
    "        \"example_topic\": example_topic,\n",
    "        \"example_response\": example_response,\n",
    "        \"topic\": topic\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"one_shot_result:\")\n",
    "print(one_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) partial 메소드 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_prompt:\n",
      "input_variables=['topic'] input_types={} partial_variables={'example_topic': '스마트폰', 'example_response': '애플: 프리미엄 시장에서 주요 경쟁사로, iPhone 시리즈로 경쟁\\n샤오미: 중저가 시장에서 강세를 보이며 글로벌 시장 점유율 확대\\n구글: Pixel 시리즈로 프리미엄 시장 진출, AI 기능 강조'} template='다음은 특정 시장에서 삼성전자의 경쟁업체를 설명하는 예시이다:\\n\\n시장: {example_topic}\\n경쟁업체: {example_response}\\n\\n이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\\n시장: {topic}'\n",
      "one_shot_result:\n",
      "시장: 인공지능 반도체  \n",
      "경쟁업체:  \n",
      "- 엔비디아(NVIDIA): AI 연산에 최적화된 GPU와 데이터센터용 AI 칩 분야에서 글로벌 선두주자, 딥러닝 및 자율주행 등 다양한 AI 응용처에 강점  \n",
      "- AMD: 고성능 GPU와 CPU를 결합한 AI 반도체 솔루션 제공, 데이터센터 및 클라우드 AI 시장에서 경쟁력 확보  \n",
      "- 구글(Google): 자체 개발한 TPU(Tensor Processing Unit)로 AI 연산 가속화, 클라우드 AI 서비스와 연계하여 차별화된 생태계 구축  \n",
      "- 인텔(Intel): AI 가속기 및 FPGA 기반 AI 반도체 개발, 데이터센터 및 엣지 컴퓨팅용 AI 칩 시장 공략  \n",
      "- 화웨이(Huawei): AI 프로세서인 Ascend 시리즈로 중국 및 글로벌 시장에서 AI 반도체 사업 확장 중, 통신 인프라와 연계된 AI 솔루션 제공\n"
     ]
    }
   ],
   "source": [
    "# Example 데이터를 반영한 부분 프롬프트 출력 \n",
    "partial_prompt = one_shot_prompt.partial(\n",
    "    example_topic=example_topic,\n",
    "    example_response=example_response,\n",
    ")\n",
    "\n",
    "print(f\"partial_prompt:\")\n",
    "print(partial_prompt)\n",
    "\n",
    "# 체인 생성\n",
    "chain = partial_prompt | llm | StrOutputParser()\n",
    "\n",
    "# One-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "one_shot_result = chain.invoke(input={\"topic\": topic})\n",
    "\n",
    "print(f\"one_shot_result:\")\n",
    "print(one_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Few-shot** 프롬프팅\n",
    "\n",
    "- **Few-shot 프롬프팅**은 AI 모델에게 2-5개의 예시를 제공하여 학습시키는 방법입니다\n",
    "\n",
    "- 이 방식은 **Zero-shot**이나 **One-shot** 프롬프팅보다 더 우수한 성능을 보여주며, 복잡한 작업에서 특히 효과적입니다\n",
    "\n",
    "- Few-shot 프롬프팅은 높은 성능을 제공하지만, 긴 프롬프트로 인한 **비용 증가**를 고려해야 합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) PromptTemplate 사용`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시장: 인공지능 반도체  \n",
      "경쟁업체:  \n",
      "- 엔비디아(미국): GPU 기반 AI 연산 시장 선도, 데이터센터 및 자율주행용 AI 칩 강세  \n",
      "- AMD(미국): 고성능 GPU 및 CPU 통합 솔루션 제공, AI 및 머신러닝 가속화  \n",
      "- 화웨이(중국): 자체 개발 AI 칩셋(Ascend)으로 중국 내 시장 확대 및 글로벌 진출 시도  \n",
      "- 구글(미국): TPU(Tensor Processing Unit)로 클라우드 AI 연산 최적화  \n",
      "- 인텔(미국): AI 가속기 및 FPGA 기반 솔루션으로 다양한 AI 워크로드 지원\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Few-shot 프롬프트 템플릿 생성 \n",
    "few_shot_prompt = PromptTemplate(\n",
    "   input_variables=[\"examples\", \"topic\"],\n",
    "   template=\"\"\"다음은 여러 시장에서 삼성전자의 경쟁업체를 설명하는 예시들이다:\n",
    "\n",
    "{examples}\n",
    "\n",
    "이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\n",
    "시장: {topic}\"\"\"\n",
    ")\n",
    "\n",
    "# Example 데이터 준비\n",
    "examples = \"\"\"\n",
    "시장: 스마트폰\n",
    "경쟁업체: \n",
    "- 애플(미국): 프리미엄 시장 주도, iPhone으로 경쟁\n",
    "- 샤오미(중국): 중저가 시장 강세, 글로벌 확장중\n",
    "- 구글(미국): Pixel로 AI 기능 강조\n",
    "\n",
    "시장: TV\n",
    "경쟁업체:\n",
    "- LG전자(한국): OLED 기술 경쟁\n",
    "- Sony(일본): 프리미엄 시장 경쟁\n",
    "- TCL(중국): 중저가 시장 공략\n",
    "\"\"\"\n",
    "\n",
    "# 체인 생성 및 실행\n",
    "chain = few_shot_prompt | llm | StrOutputParser()\n",
    "result = chain.invoke({\n",
    "   \"examples\": examples,\n",
    "   \"topic\": \"인공지능 반도체\"\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) partial 메소드 사용`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좋아! 네가 물어본 partial()은 LangChain에서 프롬프트 템플릿에 일부 변수만 미리 채워넣는 기능이야.\n",
    "Python 내장 functools.partial과 비슷한 개념이지만, LangChain에서는 PromptTemplate 전용 기능으로 제공돼."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partial_prompt:\n",
      "input_variables=['topic'] input_types={} partial_variables={'examples': '\\n시장: 스마트폰\\n경쟁업체: \\n- 애플(미국): 프리미엄 시장 주도, iPhone으로 경쟁\\n- 샤오미(중국): 중저가 시장 강세, 글로벌 확장중\\n- 구글(미국): Pixel로 AI 기능 강조\\n\\n시장: TV\\n경쟁업체:\\n- LG전자(한국): OLED 기술 경쟁\\n- Sony(일본): 프리미엄 시장 경쟁\\n- TCL(중국): 중저가 시장 공략\\n'} template='다음은 여러 시장에서 삼성전자의 경쟁업체를 설명하는 예시들이다:\\n\\n{examples}\\n\\n이제 다음 시장에서 삼성전자의 경쟁업체를 설명해주세요:\\n시장: {topic}'\n"
     ]
    }
   ],
   "source": [
    "# partial 메서드를 사용하여 Few-shot 프롬프트 템플릿 생성\n",
    "partial_prompt = few_shot_prompt.partial(\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "print(f\"partial_prompt:\")\n",
    "print(partial_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 생성\n",
    "chain = partial_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Few-shot 실행\n",
    "topic = \"인공지능 반도체\"\n",
    "few_shot_result = chain.invoke(input={\"topic\": topic})\n",
    "\n",
    "print(f\"few_shot_result:\")\n",
    "print(few_shot_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) FewShotChatMessagePromptTemplate 사용`\n",
    "\n",
    "* FewShotChatMessagePromptTemplate는 LangChain에서 제공하는 템플릿으로, **미리 정의된 고정된 예제들(Fixed Examples)** 을 프롬프트에 포함시켜 모델이 일관된 형식과 품질의 응답을 생성할 수 있도록 돕습니다.\n",
    "\n",
    "* 이 방식은 특히 특정 형식이나 구조를 가진 출력이 필요한 경우(예: JSON 형식, 특정 분석 리포트 형식 등) 매우 유용하며, 예제들이 고정되어 있어 결과의 일관성을 보장할 수 있습니다.\n",
    "\n",
    "* 단, 고정된 예제를 사용하기 때문에 상황에 따라 유연하게 대응하기 어려울 수 있으며, 모든 케이스를 커버하기 위해서는 신중한 예제 선택이 필요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from textwrap import dedent # text의 모든 줄에서 같은 선행 공백을 제거하는 함수\n",
    "\n",
    "# 예시 데이터 정의 : 뉴스 텍스트(input) + 키워드 추출 결과 (output)\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": dedent(\"\"\"\n",
    "                        정부는 의과대학 입학 정원을 2000명 증가시킬 계획의 세부사항을 이달 20일에 공개할 예정이다. \n",
    "                        지역별 의료 서비스 향상과 소규모 의과대학의 발전을 목표로, 지역 중심의 국립대학 및 소형 의과대학의 \n",
    "                        입학 정원이 최소한 두 배 가량 확대될 것으로 보인다.\n",
    "                        \"\"\"),\n",
    "        \"output\": \"의대 | 정원 | 확대\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": dedent(\"\"\"\n",
    "                        세계보건기구(WHO)는 최근 새로운 건강 위기에 대응하기 위해 국제 협력의 중요성을 강조했다. \n",
    "                        전염병 대응 역량의 강화와 글로벌 보건 시스템의 개선이 필요하다고 발표했다.\n",
    "                        \"\"\"),\n",
    "        \"output\": \"세계보건기구 | 건강위기 | 국제\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 각 예시를 포맷팅할 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"assistant\", \"{output}\")\n",
    "])\n",
    "\n",
    "# Few-shot 프롬프트 템플릿 생성\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,      # 예시 포맷팅 템플릿\n",
    "    examples=examples                   # 예시 데이터 리스트 -> 예시 포맷팅 템플릿에 적용\n",
    ")\n",
    "\n",
    "pprint(few_shot_prompt.invoke({}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 프롬프트 템플릿 생성\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 뉴스 텍스트에서 핵심 키워드 3개를 추출하는 전문가입니다.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 프롬프트 템플릿 출력\n",
    "pprint(final_prompt.invoke({\"input\": \"뉴스 기사입니다\"}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 키워드 추출 체인 생성\n",
    "chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 키워드 추출 체인 실행\n",
    "result = chain.invoke({\n",
    "    \"input\": dedent(\"\"\"삼성전자가 내년 초에 자체적으로 개발한 인공지능(AI) 가속기를 처음으로 출시할 예정이다. \n",
    "                    이는 AI 반도체 시장에서 지배적인 위치를 차지하고 있는 엔비디아의 독점을 도전하고, \n",
    "                    세계 최고의 반도체 제조업체로서의 지위를 다시 확립하려는 삼성전자의 노력으로 해석된다.\"\"\")\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) Dynamic Few-Shot Prompting`\n",
    "\n",
    "* **Dynamic Few-Shot Prompting**은 상황에 따라 적절한 예시를 동적으로 선택하여 사용하는 고급 프롬프팅 기법으로, **BaseExampleSelector**를 통해 입력값과 가장 연관성이 높은 예시들을 자동으로 선별합니다.\n",
    "\n",
    "* 대표적으로 **SemanticSimilarityExampleSelector**는 의미적 유사도를 기반으로 예시를 선택하며, 이를 통해 주어진 입력 상황에 가장 적합한 예시들만을 효율적으로 활용할 수 있습니다.\n",
    "\n",
    "* **example_prompt**를 통해 선택된 예시들을 AI 시스템이 이해하기 쉬운 형태(예: human-AI 대화 , human-function call)로 변환하여 더 효과적인 학습과 응답 생성이 가능하게 합니다.\n",
    "\n",
    "\n",
    "- **장점**\n",
    "\n",
    "    - 상황에 맞는 가장 연관성 높은 예시만을 선택적으로 활용할 수 있다\n",
    "    - 프롬프트의 길이를 효율적으로 관리할 수 있다\n",
    "    - 응답의 일관성과 품질을 향상시킬 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings \n",
    "from langchain_core.vectorstores import InMemoryVectorStore # type: ignore\n",
    "\n",
    "# 고객 문의 유형별 응대 예시를 준비\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"환불 절차가 어떻게 되나요?\",\n",
    "        \"output\": \"환불 절차는 다음과 같습니다:\\n1. 구매내역에서 환불을 신청해주세요\\n2. 반품 상품을 발송해주세요\\n3. 상품 검수 후 3-5일 내 환불이 완료됩니다\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"배송이 늦어지고 있어요\", \n",
    "        \"output\": \"불편을 드려 죄송합니다. 주문번호를 알려주시면 배송 상태를 즉시 확인해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"옷 사이즈가 안 맞아요\",\n",
    "        \"output\": \"사이즈 교환은 무료로 진행됩니다. 교환 신청 후 동일 상품의 다른 사이즈로 발송해드리겠습니다.\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"제품이 불량이에요\",\n",
    "        \"output\": \"불편을 드려 대단히 죄송합니다. 불량 부분 사진과 함께 1:1 문의에 접수해주시면 빠르게 처리해드리겠습니다.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예시 데이터를 벡터화할 텍스트로 변환\n",
    "to_vectorize = [\" \".join(example.values()) for example in examples]\n",
    "\n",
    "# Ollama 임베딩 모델 생성\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "\n",
    "# 벡터 스토어 생성\n",
    "vector_store = InMemoryVectorStore.from_texts(\n",
    "    to_vectorize,    # 벡터화할 텍스트 리스트\n",
    "    embeddings,      # 임베딩 모델\n",
    "    metadatas=examples    # 메타데이터: 예시 데이터\n",
    "    )\n",
    "\n",
    "# VectorStore에 저장된 Document 개수 확인\n",
    "print(f\"VectorStore에 저장된 Document 개수: {len(vector_store.store.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "\n",
    "# 유사한 2개의 예시를 선택하는 selector 생성\n",
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vector_store,\n",
    "    k=2\n",
    ")\n",
    "\n",
    "# 선택된 예시 확인\n",
    "selected_examples = example_selector.select_examples({\"input\":\"상품이 파손되어 왔어요\"})\n",
    "pprint(selected_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 프롬프트 템플릿 생성\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    input_variables=[\"input\"],\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=ChatPromptTemplate.from_messages([\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"assistant\", \"{output}\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "pprint(few_shot_prompt.invoke({\"input\": \"상품이 파손되어 왔어요\"}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 프롬프트 생성 \n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친절하고 전문적인 고객 서비스 담당자입니다.\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "pprint(final_prompt.invoke({\"input\": \"상품이 파손되어 왔어요\"}).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 챗봇 체인 생성\n",
    "chain = final_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 체인 실행\n",
    "response = chain.invoke({\n",
    "    \"input\": \"상품이 파손되어 왔어요\"\n",
    "})\n",
    "\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
