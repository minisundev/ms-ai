# %%
from dotenv import load_dotenv
load_dotenv()

# Langsmith tracing ì—¬ë¶€ë¥¼ í™•ì¸ (true: langsmith ì¶”ì²™ í™œì„±í™”, false: langsmith ì¶”ì²™ ë¹„í™œì„±í™”)
import os
print(os.getenv('LANGSMITH_TRACING'))

# %% 
from langchain_openai import ChatOpenAI

# LLM model
llm = ChatOpenAI(
    model="gpt-4.1-mini", 
    temperature=0.3, 
    top_p=0.95,
    )

# ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥
response = llm.invoke("íƒ„ì†Œì˜ ì›ì ë²ˆí˜¸ëŠ” ë¬´ì—‡ì¸ê°€ìš”?")

# ì‘ë‹µ ê°ì²´ í™•ì¸
response


# %%
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda, RunnableParallel
from langchain_openai import ChatOpenAI

# ëª¨ë¸ ë° ì¶œë ¥ íŒŒì„œ
llm = ChatOpenAI(model="gpt-4", temperature=0.3)
parser = StrOutputParser()

# ë””ë²„ê¹…ìš© ë¡œê·¸ í•¨ìˆ˜
def log(tag):
    return RunnableLambda(lambda x: (print(f"[{tag}] {x}"), x)[1])

# í›„ì²˜ë¦¬: ë¬¸ì¥ ëì— "ë¿…" ë¶™ì´ê¸°
add_ppyong = RunnableLambda(lambda x: x.strip() + " ë¿…")

# ê³µí†µ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (character/situation/question í¬í•¨)
template = """
ë‹¹ì‹ ì€ {character}ì…ë‹ˆë‹¤.
í˜„ì¬ ìƒí™©ì€ {situation}ì…ë‹ˆë‹¤.
ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ì§€ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}
ë‹µë³€:"""
prompt = PromptTemplate.from_template(template)

# ì²´ì¸ êµ¬ì„± (í•˜ë‚˜ë§Œ ë§Œë“¤ê³  ì¬ì‚¬ìš©)
chain = prompt | log("ğŸ§¾ Prompt") | llm | log("ğŸ“¡ LLM") | parser | add_ppyong

# ì§ˆë¬¸ 3ê°œ ì •ì˜
questions = {
    "ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œ": "ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ëœ ë°›ìœ¼ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œ?",
    "ê²Œì„ ìš•êµ¬": "ê²Œì„ì´ ë„ˆë¬´ í•˜ê³  ì‹¶ì€ë° ì €ê±° ë‹¤ í•˜ë©´ì„œ ì–¸ì œ ê²Œì„ë„ í•˜ì§€?",
    "ì²­ì†Œ íšŒí”¼": "ì²­ì†Œê°€ ë„ˆë¬´ í•˜ê¸° ì‹«ì€ë° ë­˜ í•˜ë©´ ì²­ì†Œë¥¼ ì•ˆ ë¯¸ë£¨ê³  í•  ìˆ˜ ìˆì„ê¹Œ?"
}

# ë³‘ë ¬ ì…ë ¥ êµ¬ì„±: ì§ˆë¬¸ë§Œ ë°”ê¾¸ê³  ë‚˜ë¨¸ì§€ëŠ” ê³ ì •
parallel_inputs = {
    name: {
        "character": "ë¬´ê¸°ë ¥í•œ ìƒíƒœì˜ INTP",
        "situation": "ì‚¬ë‚´êµìœ¡, ì•¼ê·¼, ìŠ¤í„°ë”” ì¼ì •ì´ ê²¹ì³ ë§¤ìš° ë°”ìœ ìƒí™©",
        "question": q
    }
    for name, q in questions.items()
}

# RunnableParallel êµ¬ì„±: ê° ì…ë ¥ì— ëŒ€í•´ ë™ì¼í•œ ì²´ì¸ì„ ì‹¤í–‰
parallel_chain = RunnableParallel({
    name: RunnableLambda(lambda x, q=input_data: q) | chain
    for name, input_data in parallel_inputs.items()
})

# ì‹¤í–‰
result = parallel_chain.invoke({})
print("\n ìµœì¢… ê²°ê³¼:")
for key, value in result.items():
    print(f"- {key}: {value}")



# %%
import asyncio
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI

# ëª¨ë¸ ë° ì¶œë ¥ íŒŒì„œ
llm = ChatOpenAI(model="gpt-4", temperature=0.3)
parser = StrOutputParser()

# í›„ì²˜ë¦¬: ë¬¸ì¥ ëì— "ë¿…" ë¶™ì´ê¸°
add_ppyong = RunnableLambda(lambda x: x.strip() + " ë¿…")

# ê³µí†µ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
template = """
ë‹¹ì‹ ì€ {character}ì…ë‹ˆë‹¤.
í˜„ì¬ ìƒí™©ì€ {situation}ì…ë‹ˆë‹¤.
ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì„ì§€ ë‹µë³€í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}
ë‹µë³€:"""
prompt = PromptTemplate.from_template(template)

# ì²´ì¸ êµ¬ì„±
chain = prompt | llm | parser | add_ppyong

# ì§ˆë¬¸ ëª©ë¡
questions = {
    "ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œ": "ìŠ¤íŠ¸ë ˆìŠ¤ë¥¼ ëœ ë°›ìœ¼ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œ?",
    "ê²Œì„ ìš•êµ¬": "ê²Œì„ì´ ë„ˆë¬´ í•˜ê³  ì‹¶ì€ë° ì €ê±° ë‹¤ í•˜ë©´ì„œ ì–¸ì œ ê²Œì„ë„ í•˜ì§€?",
    "ì²­ì†Œ íšŒí”¼": "ì²­ì†Œê°€ ë„ˆë¬´ í•˜ê¸° ì‹«ì€ë° ë­˜ í•˜ë©´ ì²­ì†Œë¥¼ ì•ˆ ë¯¸ë£¨ê³  í•  ìˆ˜ ìˆì„ê¹Œ?"
}

# ê³µí†µ ì…ë ¥ê°’
base_input = {
    "character": "ë¬´ê¸°ë ¥í•œ ìƒíƒœì˜ INTP",
    "situation": "ì‚¬ë‚´êµìœ¡, ì•¼ê·¼, ìŠ¤í„°ë”” ì¼ì •ì´ ê²¹ì³ ë§¤ìš° ë°”ìœ ìƒí™©"
}

# ë¹„ë™ê¸° ì‹¤í–‰ í•¨ìˆ˜
async def run_parallel():
    tasks = [
        chain.ainvoke({**base_input, "question": question})
        for question in questions.values()
    ]
    results = await asyncio.gather(*tasks)
    return dict(zip(questions.keys(), results))

# ì‹¤ì œ ì‹¤í–‰
if __name__ == "__main__":
    final_result = asyncio.run(run_parallel())

    print("\nâœ… ìµœì¢… ê²°ê³¼:")
    for key, value in final_result.items():
        print(f"- {key}: {value}")
